<?xml version="1.0"?>
<Container version="2">
  <Name>ComfyUI-Nvidia-Docker</Name>
  <Repository>mmartial/comfyui-nvidia-docker</Repository>
  <Registry>https://hub.docker.com/r/mmartial/comfyui-nvidia-docker</Registry>
  <Network>bridge</Network>
  <Requires>**Nvidia Driver plugin**</Requires>
  <MyIP/>
  <Shell>bash</Shell>
  <Privileged>false</Privileged>
  <Support>https://forums.unraid.net/topic/172874-support-comfyui-nvidia-docker/</Support>
  <Project>https://github.com/mmartial/ComfyUI-Nvidia-Docker</Project>
  <Overview>
ComfyUI WebUI Dockerfile with Nvidia support, built from the latest official ComfyUI GitHub release&#xD;
&#xD;
The tool will create many directories inside the "run directory": HF, data/{input,output,temp}, user, models/{checkpoints,clip,clip_vision,configs,controlnet,diffusers,embeddings,gligen,hypernetworks,loras,photomaker,style_models,unet,upscale_models,vae,vae_approx}, custom_nodes

All those folders will be created with the WANTED_UID and WANTED_GID parameters (by default using Unraid's default of 99:100) allowing the end-user to place directly into the folders their checkpoints, unet, lora and other required models.

Note that the base container comes with no weights/models; you need to obtain those and install them in the proper directories under the mount you have selected for the "run" folder.

Output files will be placed into the data/output folder within that "run" folder.

NOTE:
The first time you run the container, you will get the bottle example.
This example requires the `v1-5-pruned-emaonly.ckpt` file.
It is available for example at https://huggingface.co/runwayml/stable-diffusion-v1-5/resolve/main/v1-5-pruned-emaonly.ckpt
The way to get the WebUI to see if is to first put it in the models/checkpoints folder:
  cd /mnt/user/appdata/comfyui-nvidia/mnt/models/checkpoints
  wget https://huggingface.co/runwayml/stable-diffusion-v1-5/resolve/main/v1-5-pruned-emaonly.ckpt
After the download is complete, click "Refresh" on the WebUI and "Queue Prompt"

&#xD;
Please see https://github.com/mmartial/ComfyUI-Nvidia-Docker for further details.&#xD;
  </Overview>
  <Category>MediaApp:Photos</Category>
  <WebUI>http://[IP]:[PORT:8188]</WebUI>
  <TemplateURL/>
  <Icon>https://avatars.githubusercontent.com/u/121283862</Icon>
  <ExtraParams>--gpus all</ExtraParams>
  <PostArgs/>
  <CPUset/>
  <DateInstalled/>
  <DonateText/>
  <DonateLink/>
  <Requires/>
  <Config Name="WebUI Port" Target="8188" Default="8188" Mode="tcp" Description="" Type="Port" Display="always" Required="true" Mask="false">8188</Config>
  <Config Name="run directory" Target="/home/comfy/mnt" Default="/mnt/user/appdata/comfyui-nvidia/mnt" Mode="rw" Description="" Type="Path" Display="always" Required="true" Mask="false">/mnt/user/appdata/comfyui-nvidia/mnt</Config>
  <Config Name="WANTED_UID" Target="WANTED_UID" Default="99" Mode="" Description="UID to use for content in run directory" Type="Variable" Display="always" Required="true" Mask="false">99</Config>
  <Config Name="WANTED_GID" Target="WANTED_GID" Default="100" Mode="" Description="GID to use for content in run directory" Type="Variable" Display="always" Required="true" Mask="false">100</Config>
</Container>